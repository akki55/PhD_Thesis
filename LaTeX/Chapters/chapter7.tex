%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter.tex
%% NOVA thesis document file
%%
%% Chapter with solution applicability
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Applicability of the USE-ME conceptual framework}
\label{cha:applicability}

% 		(source: Annex 2 Section 6)


In this Chapter, we establish the relation of the \gls{useme} process we proposed in Chapter \ref{cha:useme} with the \gls{dsl} development cycle presented in Section \ref{sec:DSL}.



\section{Integration of the USE-ME conceptual framework with DSL development phases}

    \begin{figure}[]
    \centering
        \includegraphics[scale=0.37]{Chapters/Figures/useMeDSLdev.png}
        \caption{Integration of USE-ME conceptual framework with DSL development phases (taken from \cite{barisic2017UseMeJournal})}
        \label{fig:DSLIntegration}
    \end{figure}
    
    In Figure \ref{fig:DSLIntegration} we present the integration of the development process where one cycle of \gls{useme} process is performed during one development iteration. 
    In this Figure, we show how to relate one complete cycle of the \gls{useme} activities with each of the development phases. 
    %we correlate the \gls{useme} activities with each \gls{dsl} development phase. 
    
    During the \textbf{Decision} and \textbf{Domain Analysis} phases 
    of the \gls{dsl} development, 
    we perform together the \emph{Context Modelling} and \emph{Goal Modelling} \gls{useme} activities. This way, the activities can share information which is being specified and discussed in both phases while language engineers and domain experts produce the relevant DSL's modelling artefacts. For instance, the feature diagram brings useful information about environmental elements of the [Context Model], and the [Goal Model] can provide useful hints to discover usability goals and requirements, establishing a traceability link to the existing goal model produced in the \textbf{Domain Analysis}. Further, during the \textbf{DSL Design} phase the \emph{Goal Modelling} activity should be concluded and, therefore, the \emph{Evaluation Modelling} activity can start. The evaluation is dependent on the scope of the DSL modelling that should now be implemented. For instance, at an early stage, it is already possible to define the objective of the evaluation study, its process, context and discuss if the comparative evaluation should take place, or not, besides presenting the alternatives to be considered. 
    
    During the \textbf{DSL Implementation} phase, test models are created for the evaluation activity thanks to the \emph{Survey Modelling} and \emph{Interaction Modelling} activities. Further, in the \textbf{Testing/Evaluation} phase of \gls{dsl} development, the  \emph{Evaluation Execution} takes place in the \gls{useme} process.
    %However, often its execution can depend on the success of the tests. 
    Usability goal measures can depend on the provided functionalities of the \gls{dsl}s (e.g. ones needed for carrying out chosen test scenario). Therefore, these required functionalities should pass functional tests and the evaluation process should reflect the dependencies with this functional tests. For instance, the usability evaluation execution can turn to be unsuccessful, if the participants fail to perform the evaluation tasks due to technical problems.  Finally, the \emph{Report Modelling} activity can be performed and, if necessary, extended to the \textbf{\gls{dsl} deployment} phase. Finally, the [Report Model] is used to update  the previous [Goal Model] and to make a decision about the next development cycle.
    
    %Here we can share information which is being specified and discussed within the context of \gls{dsl} artefacts from this phase.
    %Here we can reuse the knowledge already specified and discussed within commonly developed \gls{dsl} artefacts. 
    %For instance, the feature diagram can bring the information about environmental elements of the Context Model and the Goal Model itself can serve to discover usability goals and requirements, and correlate them with the existing goal model. Further, during the \gls{dsl} Design phase Goal Modelling should be concluded and the Evaluation Modelling phase can start. The evaluation is dependent on the scope of the \gls{dsl} artefacts which are designed and are to be implemented in the current iteration. For instance, already early on, it is possible to define the objective of the study and specify its process and context or to discuss if the comparative evaluation should take place and which are alternatives to be considered. 
    
    %During the implementation phase, test models are created for the evaluation trough Survey Modelling and Interaction Modelling activities.
    
    %Further, in the \textbf{Testing/Evaluation} phase, the evaluation is executed. 
    
    
    However we have described a possible application of the \gls{useme}'s process that encompasses the full iteration of the \gls{dsl} development life-cycle, sometimes the complete \gls{useme} cycle can be used to cover a single \gls{dsl} development phase. For instance, during the \textbf{Domain Analysis} phase in which the requirements and objectives are not yet clear, we can model the survey which will help us to clarify the objectives from the different stakeholders. In this case, the resulting goal or context model is justified. On the other hand, during the \textbf{\gls{dsl} Design} phase, we might want to experiment with different syntax designs, and it is useful to create an assessment to evaluate their readability and understandability. Further, during an \textbf{\gls{dsl} Implementation} phase, various prototypes can be implemented and evaluated before proceeding with the \textbf{\gls{dsl} Deployment}. Finally, during the \textbf{Testing/Evaluation} phase, we might want to carry out several interdependent evaluations, e.g. previous ones impacting the extension of the [Context Model] and [Goal Model] activities.

\section{Application of USE-ME to incremental iterative DSL development}

    The \gls{useme} conceptual framework reuses the specifications along different iterations so that it is not necessary to start again from scratch with the analysis and design in each iteration.
    When introducing small extensions or changes to the \gls{dsl}s' syntax or semantics, it will be necessary to extend the existing \gls{useme} models with 'new' context instances (e.g.  new/extended user type, environment or user story). The updated evaluation goals should take into consideration the new features and/or expected usability improvements over a previous version of the \gls{dsl}. It is useful to perform the comparative evaluation with a previous version of the \gls{dsl}, to observe if an improvement happened. For instance, in the case of Visualino (see Section \ref{sec:visualino}), we reused the experimental design, evaluation process and their instruments (surveys and an interaction test model) from the previous iteration. This gave us means to comparatively analyse the results from the first and second iteration. 
    To support the organisation and planning of the iterative development, and increase the transparency of the development tasks, we can benefit from existing management tools support used for agile approaches (for instance we applied Scrum and Pivotal Tracker during the FlowSL case study (see Section \ref{sec:flowsl}). %In both of our case studies, we could reuse the parts in different evaluation assessments
    
    To trace changes in a \gls{dsl}, we can benefit from existing incremental language development approaches such as LISA \cite{Mernik2005incremental}. In this work, when the language is extended with new features, this corresponds to a new language containing specifications of the change together with the description of the previous language. For example, Mernik et.al \cite{Mernik2005incremental} extend (in the sense of object-oriented extension) a simple language describing a robot movement with a new language which also calculates when the robot will reach the final position.
    For performing this extension, there should be a concrete motivation behind.  
    For instance, in this case, new scenarios should be added to the previous workflow in a Context Model. This change does not imply the addition of the new Usability goal, but rather an extension of the existing ones with a new scenario. The evaluation design can be kept and applied to a refined scenario. On another case, also taken from \cite{Mernik2005incremental}, the authors perform an extension which supports the robot for cleaning. This change refines the previous end user profile (the user wanted 'to use a robot'), to a new profile where the end user wants 'to use a robot \textit{for cleaning}'. Also, the environment context is specified more in depth reflecting the robots for cleaning and environment where they are used. Finally, the new user stories may have different actors and will be documented under the new workflow. The evaluation should redefine the usability goals, and probably create new ones which take into consideration the new context. 
    
    Early evaluations and extensions without a significant change of context or usability goals, can be performed with domain experts, while other users should be involved in evaluations later on. By performing early assessments with more available users the evaluation design and its metrics are being validated, and a risk of not obtaining a return of the investment in extensive evaluations is lowered. Also, as mentioned previously, bigger investment into usability evaluations should be applied to the \gls{dsl}s which target a wide scope of the end users, especially those who are not exactly reflected by the domain experts profile which is included in the development. For the 'in house', or small \gls{dsl}s developed for a very small set of users, especially those included in its development process, an application of our systematic approach as a whole might be too expensive, but the analysis procedure can still be found useful.

\section{Applicability of the conceptual framework outside of the scope of model-based DSLs under development}

    \subsection{Previously released DSLs}
        We followed the \gls{useme} conceptual framework on two industrial \gls{dsl}s. In both case studies, we were not directly involved in the development of the \gls{dsl}s but participated as evaluation experts. These \gls{dsl}s were developed from scratch: an internal \gls{dsl} based on Ruby \cite{barisic2014flows}; an external \gls{dsl} described in Section \ref{sec:visualino}. We chose these case studies as we did not find many examples of usability evaluations involving end users early in the \gls{dsl}s' development cycle (see Chapter \ref{cha:related}). If we think of \gls{dsl}s already existing in the market, the \gls{useme} process will be similar to the process used with \gls{dsl}s which are under development. However, with previously released \gls{dsl}s, it should already be clear {\textbf{Who}} are the users, {\textbf{What}} are the user stories and {\textbf{Where}} the \gls{dsl} is being used. It is expected that it will be possible to reuse most of this knowledge from already existing artefacts and specify the usability goals and metrics in an easier fashion. During the evaluation modelling, the assessments can be planned to be performed automatically (e.g. with automated usage data collection) and remotely. With a large number of regular users, more data can be obtained. 
        
        On the other hand, if there is still information missing to create a complete context or goal model, it is still possible to plan the evaluation, by sticking to the information that exists. 
        For instance, if there is no formal specification/documentation of the workflows, this information can be omitted. However, the evaluation model will be designed accordingly, e.g. to evaluate the satisfaction with a language or the readability of design concepts. It is also possible to create an interaction model which captures just 'random' roll-back cycles (semantic errors) during a common use of a product (e.g. placing and deleting certain commands repetitively in a certain sequence can help identifying misinterpretation issues of a concrete syntax element). 

    \subsection{Grammar-based DSLs}
        Both of our case studies were developed by using meta-modelling tools (MetaEdit and Eclipse EMF, respectively). Our process is not restricted to model-based \gls{dsl}s and could, in principle, be applicable also to grammar-based \gls{dsl}s or even to \gls{gpl}s. However, this would require adapting our prototype to cope with their architecture. This would be feasible but is beyond the scope of this thesis. It would be necessary to apply modelling techniques (e.g. reverse engineering), to create certain artefacts (e.g. goal model,  \gls{uml} diagrams, etc.).
        
        %Finally, it is possible to extend this systematic approach to the other context (GPLs or \gls{ui}) present itself. The only additional implication for this group of software products is to encourage this community to narrow their scope to something that could be domain-specific. 

\section{Taking the role of Expert Evaluator during the DSL development cycle} 
    
    The modelling activities in our conceptual framework are presented as activities of an Expert Evaluator which, in practice, is not typically included in the \gls{dsl} development process. We mentioned in Section \ref{sec:Usability} that this \gls{hci} expert usually implements complex experimental usability evaluation studies. The \gls{hci} expert profile includes comprehension of user profiling, experimental approaches and usability evaluation methods. However, when applying the proposed systematic approach, these kinds of experts may lack the knowledge about model-driven methods and requirements engineering, and it may be not trivial for them to grasp the modelling concepts and tools. Therefore, these experts should be introduced to abstraction modelling and trained to use the modelling support with a focus on mastering the modelling concepts present at the \gls{useme} conceptual framework (e.g. goal modelling, process modelling,  \gls{uml} modelling). 
    % future work: testing the tool with the experts (\gls{hci}, \gls{sle})
    
    Moreover, we found that in case there is no person included in the development team with evaluation expertise, the knowledge of these experts can be transmitted to a typical \gls{dsl} Engineer through the \gls{useme} conceptual framework. The conceptual framework was validated by researchers from NOVA-LINCS research centre, who are experts in  \gls{mdd} and \gls{dsl} development and were not involved in the conceptual framework development. Some of them are also knowledgeable about the experimental software engineering and requirements engineering. These experts provided valuable feedback and improvement suggestions over the conceptual framework. However, people with high level of experience might also not be available during the \gls{dsl} development process to take the role of Expert Evaluators. Inexperienced engineers can still be suitable for the Expert Evaluator role in the \gls{dsl} development project. As a proof of concept, we performed a preliminary pilot evaluation of the conceptual framework prototype with master students in informatics who had knowledge about \gls{mdd} and \gls{dsl} development \cite{barisic2017pilot}. However, these engineers should be trained in user profiling, usability evaluation methods, experimental software engineering and requirements engineering practices.
    
    %In both of our industrial case studies, we were not directly involved in the development of the \gls{dsl}s but participated as evaluation experts. We had expertise in both \gls{mdd} and usability evaluations. %However, this expertise may not be available during a regular \gls{dsl} development. When choosing a suitable candidate who will take the role of an Expert Evaluator, it is important to be sure not to include this person in other \gls{dsl} development activities. If this person is working too close to Domain Experts and other Language Engineers, this person will raise mostly concerns of the \gls{dsl} development stakeholders and is not able to focus on concerns related to the end-users. 