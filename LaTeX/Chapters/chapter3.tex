%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter3.tex
%% NOVA thesis document file
%%
%% Chapter with a related work
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Related work}
\label{cha:related}

The related studies show that the scientific community is still not making use of the current solutions offered by the software engineering community \cite{kelly2008domain}. 
The requirements discovery process is difficult because \gls{dsl}s are  exploring new domain-related problems. Therefore, in most of cases requirements cannot be
known in advance; they change as knowledge changes \cite{Segal2008DevelopingSoftware}.
These constraints affect the applicability of many of the traditional software engineering practices and partially explain why scientists tend not to use
them \cite{Kendall2008DevelopmentStudy}. 

\section{General-purpose usability evaluation approaches}

    In the context of \gls{gpl}s, comparing the productivity impact of using different languages during the software development process has some tradition \cite{Prechelt2000IEEEComputer}. Some of the common techniques are the use of a popularity index \cite{Cook2007Book}, the cognitive dimensions framework \cite{green1996usability}, or heuristics based on the studies of cognitive effectiveness for visual syntax \cite{moody2009evaluating}.  These methods can be reused  when these techniques are identified as relevant for the usability of a \gls{dsl} (e.g. Moody's work on cognitive effectiveness can be reused  if a visual concrete syntax is given to the target \gls{dsl}). When usability problems are identified too late, a common approach to mitigate them is to build a tool support that minimises their effect on the users productivity \cite{bellamy2010using}.
    
    \gls{gpl} users are typically technically-oriented programmers, with good understanding, skills, and experienced in computer science and technology. However, the understanding of domain concepts is also necessary to develop programming solutions. On the other hand, \gls{dsl}s are meant to reduce the direct use of computation concepts by putting the focus on the domain concepts. As such, \gls{dsl}s are expected to be used by a target population familiar with the domain concepts, but not necessarily experienced with computer science and technology (e.g. experts from physics, chemistry, finance, management, etc.). The evaluation criteria for \gls{dsl}s need to be appropriate for their target users, as well as to their technical, social and physical environment.
    
    We can build on existing methodologies and tools to assess the usability of \gls{ui}s \cite{Barisic2011INFORUM} and adapt them for programming languages (as we discussed in previous Chapter). 
    Existing \gls{ui} practices, due to the wide spectrum of the context of use that they target, makes it hard to interpret what the collected information means. While for \gls{dsl}s the population of users tends to be smaller and less diverse. As such the sampled subjects are likely to have a higher proximal similarity to the remaining elements of the population they were sampled for, mitigating the external validity threat.

\section{The state of practice in DSL evaluation}

    Some studies  address specific quality characteristics for \gls{dsl}s by performing  experimental evaluations after implementing the language. Haugen et al. \cite{Haugen2007DSM} present a structured questionnaire based on three dimensions of a \gls{dsl}: expressiveness, transparency, and formalization. Merilinna and Parssinen \cite{Merilinna2007DSM} investigate the benefits of using \gls{dsl}s by making experimental comparisons between the \gls{dsl} approach and traditional approaches. Kosar et al. \cite{Kosar2010}  independently evaluated several \gls{dsl}s and are mostly concerned with program comprehension, correctness and efficiency, while using the \gls{dsl}s, when compared with using \gls{gpl}s. A detailed analysis of their data could be used to identify opportunities for improving the tested \gls{dsl}s. Kieburtz et al.'s \cite{kieburtz1996software} experiment addresses \gls{dsl} comparative evaluation as part of the concern with flexibility. Murray's experiment  \cite{murray2000kaleidoquery}  explicitly looks for opportunities for improving the respective \gls{dsl}s under scrutiny by taking learnability, understandability, usability, user satisfaction and language evolution as improvement goals. K{\"a}rn{\"a} et al. \cite{karna2009evaluating} evaluate a \gls{dsl} solution in an industrial case focusing on the productivity and usability. They first determine the objectives for the creation of the \gls{dsl} and then collect data via controlled laboratory studies. In general, existing assessments are performed with a final version of a \gls{dsl} when potential problems are expensive to fix.  Our research aims to introduce language evaluation concerns early in the \gls{dsl} development process so that problems can be found 'on-time' and fixed at a fraction of the cost it would take to fix them if detected only after the implementation.
    
    Gabriel et al. \cite{Gabriel2010CIBSE} present a systematic review emphasizing the reduced concern on the evaluation of \gls{dsl}s. This work highlights the state of practice and increases awareness to the shortcomings in research  regarding this problem. Kosar et al. \cite{kosar2016domain} performed a systematic mapping study of grammar based \gls{dsl}s covering the period from 2006 till 2013. They concluded that the \gls{dsl} community focuses more on the development of new techniques/methods rather than investigating the integrations of \gls{dsl}s with other software engineering processes or measuring the effectiveness of \gls{dsl} approaches. According to Kosar's study, the primary studies usually discussed the following three DSL development phases: domain analysis, design and implementation, whilst validation and maintenance have been rarely presented (see Figure \ref{fig:kosarMap}). In many primary studies authors found a brief section on domain analysis identifying the main concepts of DSL under development followed by the design of DSL syntax and semantics and finalizing with implementation details.
    This study explicitly presents a clear concern regarding the lack of \gls{dsl} research within the validation phase, in particular controlled experiments.  Also, it is pointed that  \textit{"\gls{dsl}s had rarely been validated (e.g., by end-users) assuming that the developed \gls{dsl}s were perfectly tailored for domains, as well as fitting end-users requirements. However, this is far from true. \gls{dsl}s under development should be empirically validated, if possible with the collaboration of end users, as well as assessed considering existing research from Psychology of Programming"}.
    

%Recent attempts in this direction are works [2, 3, 11, 60].
    \begin{figure}[h]
        \centering
            \includegraphics[scale=0.5]{Chapters/Figures/KosarMapping.png}
            \caption{Research distribution in DSL development phases (taken from \cite{kosar2016domain})}
            \label{fig:kosarMap}
        \end{figure}

    However, some authors did tackle above mentioned problems. Kolovos et al. \cite{kolovos2006requirements} list the core quality requirements for a \gls{dsl}. Hermans et al. \cite{Hermans2009Models} identify success factors for designing \gls{dsl}s by performing an empirical study. Wu et al. \cite{wumeasuring} present an approach to determine the effort while using \gls{dsl}s during application development, contributing to the classification of the effort and proposing of related metrics. Kelly and Pohjonen \cite{Kelly2009IEEESoftware} discuss worst practices for creating \gls{dsl}s which developers should avoid, based on industrial case studies. McKean and Sprinkle \cite{mckean2012heterogeneous} present criteria that will help in selecting a \gls{dsl} or any other approach to be used in system development. According to Nishino \cite{nishino2011misfits}, if developers do not have the suitable domain knowledge during \gls{dsl} development, inappropriate abstractions occur as a consequence of conceptual misfits.
    He proposes to identify usability problems by analysing a set of cognitive dimensions proposed by Green et al. \cite{green1996usability}. 
    However, this approach does not indicate how to proceed with applying changes in a potential existing analysis model, how to evolve the design models, or the implementation infrastructure. Further, the approach addresses only partially the testing of usability problems by usability experts, and it does not include end users in the evaluation. Kahraman \cite{kahraman2013framework} proposed a Framework for Qualitative Assessment of \gls{dsl}s that adapts and integrates the ISO/IEC 25010 standard, maturity level evaluation approach and the scaling approach into a perspective-based model. This framework supports the choice of quality goals from the different stakeholders' perspective, but does not to include the Domain User concerns. Finally, H\"{a}ser \cite{haserIntergratedTool}
    provides an integrated end-to-end tool environment to perform controlled experiments in \gls{dsl} engineering.  The environment  supports language design and  steps of experimentation, i.e., planning, operation, analysis and interpretation, as well as presentation and package. Controlled experiments have the potential to provide appropriate, data-driven decision support for language engineers to compare different language features with evidence-based feedback. However, this kind of usability assessments is not always cost effective in early phases of language development.
    
    More recent, in 2017, Rodrigues et al. performed systematic literature review related to usability evaluation of \gls{dsl}s \cite{PoltronieriRodrigues2017UsabilityReview}. The authors intended to find out what was the importance of usability considered during the \gls{dsl} development. Further, they identify what were the evaluation techniques that were applied in the context of \gls{dsl}s and what were the problems and limitations identified during the \gls{dsl} usage. They reported the 12 primary studies which address the topic, of which four are authored by the thesis author, namely: Sinha et al. \cite{Sinha2006AnTechnique} , Bari\v{s}i\'{c} et al. \cite{Barisic2012plateu}, Bari\v{s}i\'{c} et al. \cite{barisic2012sedes}, Bari\v{s}i\'{c} et al. \cite{barisic2014flows}, Rouly et al. \cite{Rouly2014UsabilityNon-Programmers}, Ewais et al. \cite{ewais2014usability}, Bari\v{s}i\'{c} \cite{barisic2012book}, Gibbs et al. \cite{Gibbs2015ASpecialization}, Teruel et al. \cite{Teruel2014AEvaluation}, Kaba\v{c} et al. \cite{Kabac2015AnUsability}, Cuenca et al. \cite{Cuenca2015ACode}, Albuquerque et al. \cite{Albuquerque2015QuantifyUsability}. Based on the results, authors present \gls{dsl} usability evaluation taxonomy. Usability evaluation methods which were used are classified as observation methods (A/B test and usability test), inspection methods (heuristic evaluation) and walkthrough. The most of the primary studies were identified to use the experimental study as an empirical method, while the assessments used quantitative and qualitative data types. Regarding evaluation instruments, most of the primary studies used Questionnaire and Interview, while other reported instruments were User Observation, Recording User Action and Heuristic checklists. Two studies used cognitive dimensions framework. Finally, the review identified the following evaluation metrics: Ease of Use, Efficiency, Understanding/ Learning, Effectiveness, Usage Satisfaction, Productivity, Flexibility, Effort/Competition Time, Task Error, Representatives, Error Rate, Perceived Complexity and Intuitiveness. Based on the results of the systematic literature review, authors stressed the necessity for the framework which will support the \gls{dsl} usability evaluation. 

\section{Applying UCD into design of visual languages}
    We performed a systematic literature review of the research literature of \gls{dsl}s development reports in the period of 2009 to 2014 of Journal of Visual Languages in \cite{barisicDSLSLR2015}. The quest was to identify if they report domain analysis and/or evaluation of developed \gls{dsl}.
    Based on results of performed analysis we concluded there is increased awareness of usability evaluation in a field of visual \gls{dsl}s, when compared to results obtained by Gabriel et. al \cite{Gabriel2010CIBSE}. 
    The majority of the papers did systematically report the realization of some kind of experimental evaluation as well as domain analysis. However, the domain analysis reports donâ€™t reveal a systematic approach to its performance, or even the characterization of the solution regarding its technical underneath environment. This makes us ask how much effort will be necessary for integrating DSLs into working environment. Studies are usually reporting a state-of-the-art in a domain, review of good practices, comparisons to previous approach or theoretical analysis. On another hand, most of the languages are developed to be an extension of the previous approach. This is good practice that indicates that actually the conceptual domain models are being partially reused, however, it is rare to find insight into which of these concepts are kept the same and which were changed.
    
     \begin{figure}[h]
        \centering
            \includegraphics[scale=0.45]{Chapters/Figures/chartESE.png}
            \caption{Placement of the evaluation assessments into development of visual DSLs (taken from \cite{barisicDSLSLR2015})}
            \label{fig:chartESE}
        \end{figure}
        
    Concerning the placement of the evaluation assessments into \gls{dsl} development process, we could get the idea in which phases they took place for the majority of the papers (see Figure \ref{fig:chartESE}). The practice is still similar as reported by Gabriel et. al, to make evaluations after implementation (over 40\%). However, almost 40\% of them are introducing evaluation assessments already during the domain analysis or design phase and after implementation, while few  of those even claiming to make it iteratively.
    This early assessments are often introduced by performing heuristic evaluation \cite{Bauleo2014577, Gatto2014, Giordano201041} or using cognitive dimension analysis \cite{Grundy2004JVLC, Blackwell2014545, Neumann200916, Schmieder201098} often involving evaluation experts. On another hand, most of the evaluations are involving the end-users into at least one of the assessments. However, common practice is to perform this with student surrogates for novice users, specially for the assessments of working prototypes or final product. On another hand, the expert users are often used for early assessments.
    
    We highlight the studies which reported explicitly to address the \gls{ucd} during their development:
    Neumann \cite{Neumann200916} investigates rule-based, end-user strategy programming by introducing a domain-specific, end-user programming environment to allow football coaches to create animated football scenarios and by associating strategy information with virtual football players. This study contributes further by putting into evidence the usefulness of Natural Programming design process, which applies principles of \gls{ucd} \cite{pane2002programming}. 
    Aghee \cite{Aghaee2014414} iteratively evaluated a \gls{dsl} for developing of Mashups using formative evaluations. Angelini \cite{Angelini2014394} presents an innovative visualization environment, which makes more effective the information retrieval performance evaluation and failure analysis. Environment exploits visual analytic techniques in order to foster interaction and exploration of the experimental data. The environment has been validated through a user study involving experts which showed to eases the interaction with experimental results, supports users along the evaluation process and reduces the user effort.  Ardito \cite{Ardito2014278} presents an approach where a composition platform enables the extraction of content from heterogeneous services and its integration. Bauelo \cite{Bauleo2014577} presents a visual query system, which allows users to graphically build queries over data streams and traditional relational data. The system has been designed and implemented following the \gls{ucd} approach.  Two different releases of the system have been incrementally and iteratively designed and evaluated. The first release has been evaluated using heuristic evaluation. The second release, whose design was a refinement based on the results of the foregoing heuristic evaluation, was evaluated by several users. Moreover, a comparative evaluation involving users has been conducted on the second release. The approach has been employed in real industrial scenarios, and turn to be beneficial for adoption of product by their users.
    Danado \cite{Danado2014297} creates a visual mobile end user development framework which allows end users without programming background to create, modify and execute applications, and provides support for interaction with smart devices, phone functions, and web services. Fogli \cite{Fogli201247} describes a meta-design approach to transfer the development of government-to-citizen services from professional software developers to administrative employees, without forcing employees to acquire any programming skills. 
    
    We find that these examples are valuable, although they lack a systematic experimental assessment in most of the cases. However, evaluation practice found in these works could be made model-driven, systematic and extended to \gls{dsl}s in general.


\section{Leveraging domain experts in the DSL development}

    Finally, we present  attempts to solve the usability problems by taking into account end-users needs during \gls{dsl} development. However, these approaches are in most cases just applicable in the domain analysis and language design phase, namely supporting collaborative development of the abstract and concrete syntax with end-users. However, these examples do not fully represent the complete domain model explicitly (scope, terminology, concepts, and commonalities and visibilities).  Also, the profile of the users which are included, or knowledge sets which are necessary, are essentially domain experts.
    
    The motivation of Perez et al. [66] is to involve end-users in a \gls{mdd} process. Since end-users do not usually know about \gls{dsl}s and modelling tools, as professionals do, their goal is to develop a modelling language with a good usability. However, specific requirements and needs of the target end-users are not directly communicated during the DSL development process. In fact, the proposal always creates visual \gls{dsl}s to improve usability, which may not be the best approach for some end-users.
    The goal of Wuest et al. \cite{wuest2013semi} was to facilitate the meta-modeling activity to non-experts 
    by creating FlexiSketch, an environment for modelers and end-users to design together the examples of the domain using sketches. 
    These examples are used for the creation of the \gls{dsl} syntax, both the abstract syntax and the concrete syntax. 
    Similarly, Cho et al. \cite{cho2012creating}, provide a friendly solution for end-users to describe domain examples, the creation of the \gls{dsl} syntax, and the semantic restrictions. Approach supports the domain examples sketches which are transformed into graph representations and then, an inference engine which obtains the metamodel from those graphs.
    Kuhrman et al. \cite{kuhrmann2013rapid} want to bring together \gls{dsl} developers and domain experts when developing \gls{dsl}s in complex application domains. 
    Their work provides a \gls{dsl}, named 'PDE language', 
    %as a friendly environment to facilitate the creation of \gls{dsl}s to both end-users and developers. 
    %However, authors acknowledge that usability is still an issue to improve and only end-users with some \gls{dsl} development experience are able to accurately understand the whole environment.
    % During  Domain Analysis end-users are involved by means of sketches, more specifically, through the graphical interface of the PDE language editor. 
     %However, like the previous works, Domain Model Specification is not supported (NS), since no scope, terminology, concepts, and commonalities and variability are explicitly described.
    % Although the PDE editor 
     which provides a visualization model editor with different views to facilitate the participation of domain experts in  the design of concrete syntax.
     %, actually end-users can only participate in the concrete syntax design by selecting their
    %graphical elements. As authors admit, some views are still difficult for end-users, such as the view for refining the abstract syntax meta-model or the view for programming validation functions.
    %Finally, no further stages are presented after the implementation of the \gls{dsl} editor.
     Sanchez-Cuadrado et al. \cite{Sanchez-Cuadrado2012} wanted to support the use of informal drawing tools as a friendly interface that facilitates the meta-modeling task. 
     %The goal of this work is enhancing end-user participation within the \gls{dsl} development process by using these tools to sketch a set of domain examples. 
     The difference of this work in respect to the others is the approach used to generate the meta-model from the domain examples sketches.
    %In this approach, during Domain Analysis, end-users are encouraged to draw a set of sketches that represent examples of their domain and designers are responsible to annotate these examples with additional domain information (Figure 3.4). An example of domain annotation is the intention of a graphical element of a domain example.
    %From examples and annotations, the corresponding metamodel that complies with these domain examples is induced. 
    This meta-model is obtained iteratively, one example at a time, in which developers are able to assess the evolution of the meta-model and the specific effects of each domain example over the meta-model.
    If some changes have been applied, a procedure checks for possible mismatches between the final meta-model and the domain examples.
     Nevertheless, none of the above approaches makes explicit the domain model details, nor addresses evaluation  activities of \gls{dsl} development.
    %The proposal only focuses on the domain analysis and the metamodeling task but other \gls{dsl} development activities are not addressed.
    
    The motivation of Canovas et al. \cite{izquierdo2013enabling, izquierdo2013engaging, Izquierdo017Collaboro} was to highlight the importance of the end-users role in the definition of \gls{dsl}s and provide means to enable the collaboration between end-users and developers in the context of \gls{dsl} development. 
    With this aim, they proposed a community-driven \gls{dsl} Collaboro, to encourage end-user participation in the definition of \gls{dsl}s.
    %In order to involve end-users, they take the traditional \gls{dsl} development process as a basis and modify each stage to be iterative, i.e. the process only proceeds with the next stage when end-users completely agree with the outcome of the current stage. In each stage, end-users and developers collaborate to create the different \gls{dsl} artefacts.
    %The collaboration among end-users and developers is supported by a \gls{dsl} named . 
    Collaboro describes the elements of the collaborative activity (comment, vote, solution, etc.) and the elements of the abstract and concrete syntax of a \gls{dsl} (entity, attribute, relationship, textual notation, etc.). These elements are used to track the evolution of both the abstract and concrete syntax.
    The collaborative development starts after requirements gathering, when developers design a preliminary abstract and concrete syntax. End-users are able to comment, propose solutions, and vote other participants opinions and proposals. This interaction continues until the syntax, after all the changes are proposed and applied.
    %This work provides a collaborative infrastructure to design the abstract and the concrete syntax of a \gls{dsl}. 
    % First, end-users (aided with developers) use informal drawing tools to create domain examples. Second, from those domain examples, the abstract syntax
    %meta-model is induced according to the approach of Sanchez-Cuadrado et al. Third, after obtaining the metamodel, the collaborative infrastructure Collaboro, is used by end-users and developers to propose potential changes to the abstract syntax metamodel. Additionally, a recommender system also identifies potential changes according to metamodel-quality patterns. Fourth, from all the proposed changes, some of them are accepted and incorporated to the abstract syntax. The proposal iterates over the steps three and four until no more changes are pending. Finally, in the fifth step, the final version of the abstract syntax metamodel is implemented.
    %the approach starts from a metamodel obtained from end-users participation, instead of starting the proposal from a metamodel proposed by developers, and then, a collaborative environment allows discussion and tracking of syntax changes.
    In summary, the main contribution of this work as a whole, in contrast of previous works, is the use of friendly mechanisms, such as the use of an informal panel and the use of examples, as a way to reason about the domain and the abstract and concrete syntax.
    %Likewise, Semantics Specification (restrictions and behavior), Testing, and maintenance are not supported (NS).
    Villanova \cite{villanueva2014involving} made a significant contribution in introducing agile methodologies in \gls{dsl} development. %However, it is known that even in this area the quality assurance  and usability assessment also problem in this area. 
    Methods like customer reviews and demonstrations that are used in Scrum are not often validated by real end-users, but mostly with managers or 'buyers' of the software. 
    % Scrum suggest the maximum of two weeks iterations, that doesn't seem to be feasible always to fit all MDD development approach into this small time restrictions. MDD implementation using workbenches is already in most cases halfway automatized but we can suggest using iteration for each development phase, by this sometimes repeating the same \gls{dsl}  development phase more times when needed.
    The practice of introducing a definition of \textit{Done} brought by the agile practices promotes demonstrations to the customers and a feedback collection. However,  demonstrations and questionnaires are not sufficient to test product usability with the customers. 
    Indeed, without using a product, end users will have a hard time identifying where they are likely to make mistakes and use the product inappropriately. While they can provide some feedback on their satisfaction regarding language construction (as far as they can observe it from the demonstration), they will not be able to provide feedback on their efficiency and effectiveness while using it. 
    
    The mentioned works do not address how to prioritize user recommendations, for the next iterations of the \gls{dsl} development. We could leverage user profile to support prioritization of requirements for the next iterations, which would lead to more timely and usable improvements in the \gls{dsl}.
    We need to be aware that the users while using software products are often not aware of their mistakes and inappropriate use of the product. Methods which support collection of a user feedback regarding their satisfaction with provided interface elements or functionalities, are valuable in the beginning of the development cycle. However, later on it is necessary to obtain as well proofs about their efficiency and effectiveness while solving a domain related problems.
    %The important aspect of Villanova work (and others) is that it is not clear how to make decisions in between each of iterations for \gls{dsl} about priorities.  If we define requirements and goals by knowing the groups that their target and prioritization of the same are a way to bring a quickly as the possible product that is timely and is usable. 
    The experimental evaluations with end users are expected to uncover the set of the  mostly needed functionalities in the application area that are possible to be developed in the following cycle  when  considering the technical restrictions (e.g. lack of informational database to support the functionality, need to develop previous modules in order to support the functionality). The domains for which \gls{dsl}s are developed are constantly changing, so prioritizing evaluation can help in providing timely solutions that are usable to their target end-users.
    %making more quicker deliveries are not assuring providing the solutions that are usable by end-users.
    However, the specific requirements and needs of the target end-users need to be evaluated by including them in systematic evaluations during the \gls{dsl} development process.
